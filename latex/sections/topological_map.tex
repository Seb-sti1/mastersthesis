\chapter{Topological map creation}\label{ch:topological-map-creation}

As discussed in~\ref{sec:problem-at-hand}, the main purpose of using a topological map is to retain only the necessary information about the environment.
A traditional map scales quadratically with the area’s width, whereas a topological map grows linearly with the number of nodes.
These nodes, typically representing intersections, are key locations where information is gathered.
The number of generated nodes is an important factor, as it is the main parameter controlling the final map size.
The robustness of the local navigation system directly constrains the required number of nodes: more robust navigation
allows for fewer nodes, while less capable systems require denser node placement.
However, beyond a certain point, a minimal number of nodes is always necessary regardless of local navigation performance.


\section{Fast Color/Texture Segmentation For Outdoor Robots}

In~\textcite{rasmussen_appearance_2009}, the team at the University of Delaware uses the method described in~\textcite{rufus_blas_fast_2008},
\gls{lidar} data, and geometric constraints to detect a forest trail and make an \gls{ugv} follow it.\\
As both articles seemed to give promising results, a first attempt was made to segment \gls{uav} imagery using the method
described in~\textcite{rufus_blas_fast_2008}.

At this point, no dataset using \gls{u2is}' \gls{uav} was available, so the publicly available~\textcite{noauthor_aukerman_nodate} dataset was used.
It is a dataset of Aukerman Park\footnote{15561 York Rd, North Royalton, OH 44133, United States}, containing 78 images
(4896 × 3672) captured with a Sony DSC-WX220.
It was chosen because it contains trails, grass, trees, gravel/sand paths, and asphalt roads from an aerial perspective,
which seemed like a good variety of terrains (see~\Cref{ch:aukerman-park-overview}).

The method from the article~\textcite{rufus_blas_fast_2008} starts by converting the input RGB image to the \textit{CIE-Lab} color space.
Then, for each pixel, descriptors are computed using~\Cref{eq:fast_color:descriptor}, where the first three features
describe color while the remaining eight describe local texture.
\begin{align}
    \label{eq:fast_color:descriptor}
    p_{i,j} = \begin{bmatrix}
                  W_1 \times L_c         \\
                  W_2 \times a_c         \\
                  W_2 \times b_c         \\
                  W_3 \times (L_1 - L_c) \\
                  \vdots                 \\
                  W_3 \times (L_8 - L_c) \\
    \end{bmatrix} \text{$W_i$ are weights that can be adjusted}
\end{align}

The pixel descriptors are first grouped using the well-known k-means clustering algorithm, which organizes similar
pixels---those that are close in the descriptor space---into clusters.
Each cluster's centroid, referred to as a \textit{texton}.
These \textit{textons} serve as representative that capture local color and texture features.
After clustering, an outlier filtering step is performed to remove descriptors that lie too far from their associated
\textit{texton}, ensuring better cluster consistency.
Next, for each pixel, a local histogram is computed by analyzing the distribution of \textit{textons} within a neighborhood
window centered on that pixel.

\begin{figure}[ht!]
    \centering
    \begin{subfigure}[t]{.29\textwidth}
        \includegraphics[width=.99\textwidth]{illustrations/topological_map_creation/fast_color_raw1}
        \caption{Raw image used as input}
        \label{fig:fast_color:raw_image}
    \end{subfigure}
    \hfill
    \begin{subfigure}[t]{.69\textwidth}
        \includegraphics[width=0.99\textwidth]{illustrations/topological_map_creation/fast_color_hist1}
        \caption{2D histogram for three given \textit{textons}. The greener, the higher the density of the \textit{texton}.}
        \label{fig:fast_color:histograms}
    \end{subfigure}
    \caption{Intermediate results of the algorithm.}
    \label{fig:fast_color:intermediate_histograms}
\end{figure}


In this framework, \textit{textons} provide a fine-grained (micro-level) description of the image, while the histograms
represent the spatial composition and density of different \textit{textons} in a local region.
The initial step of extracting \textit{textons} ensures that the algorithm can adapt to and segment very different
environments by generating a representation tailored to the specific visual characteristics of the input.
The second step, which involves constructing local histograms, begins to reveal structural information about the scene.

\Cref{fig:fast_color:intermediate_histograms} presents representative histograms of three \textit{textons} obtained from
the input image shown in~\Cref{fig:fast_color:raw_image}.
As seen in~\Cref{fig:fast_color:histograms}, the spatial distribution (density) of \textit{textons} highlights distinct areas in the image.
For instance, the first histogram shows high density over grassy areas and low density over paths, the second appears to
emphasize trees, and the third again highlights grassy regions.

Following this, new feature vectors are constructed for each pixel, where each feature corresponds to the value of one
of the histograms at that pixel location.
To further abstract this information, the local histograms---through these new feature vectors---are clustered again using the
k-means algorithm, grouping together similar regional patterns based on their distribution of \textit{textons}.
In this way, the final clustering step operates not on raw local patterns, but on higher-level features that
describe the composition of the surrounding area.
This shift allows the segmentation to capture more meaningful regional structures rather than isolated texture or color variations.

Finally, a refinement step employs the \gls{emd} to merge histogram clusters whose centroids are too close in distribution
space, reducing redundancy and enhancing the semantic consistency of the segmentation.
This step compensates for the limitation of the k-means algorithm, which always produces a fixed number of $k$ clusters,
regardless of the actual number of meaningful regions in the image.
By merging clusters that are too similar, the final segmentation becomes more representative of the true structure of the scene.
Adjusting the minimum distance threshold for merging allows control over the segmentation granularity.


In the example shown in~\Cref{fig:fast_color:emd_10}, clusters one, two, and four appear to correspond
to paths and grassy areas, while the remaining clusters have no well-defined meaning.
Varying the parameters---such as the number of \textit{textons}, the number of clusters for the histograms, the histogram
window size, etc.---produced different results, but none seemed clear or reliable enough to be used for accurately segmenting
traversable terrain for topological map construction.\\
This seems like the main limitation of using k-means to find textons to find very specific areas in a picture.
Given a properly and exhaustive dataset, an interesting change would be to define textons for different surfaces
and create the initial cluster using K-Nearest Neighbors (KNN) or similar supervised algorithms instead of k-means.
The idea is that this would prioritize low-level patterns relevant to this use case, potentially enabling the algorithm
to extract more meaningful and task-specific information.

% TODO another limitation it is that is slow

\begin{figure}
    \begin{subfigure}[t]{0.45\textwidth}
        \includegraphics[width=0.99\textwidth]{illustrations/topological_map_creation/fast_color_before_emd}
        \caption{The clusters before merging using the \gls{emd}. minimal distance of 0.}
        \label{fig:fast_color:before_emd}
    \end{subfigure}
    \hfill
    \begin{subfigure}[t]{0.45\textwidth}
        \includegraphics[width=0.99\textwidth]{illustrations/topological_map_creation/fast_color_emd_10}
        \caption{Final clusters using \gls{emd} minimal distance of 10.}
        \label{fig:fast_color:emd_10}
    \end{subfigure}
    \hfill
    \caption{Final clusters given two values of minimal \gls{emd}.}
    \label{fig:fast_color:final_cluters_comparaison}
\end{figure}


\section{Detecting trees in order to find traversable region}

As mentioned in the previous section, having a dataset to improve different methods by applying machine learning, seems
like an interesting idea to try.
For instance,~\textcite{zhang_dual-bev_2025} uses a retrained version of U-Net~\cite{ronneberger_u-net_2015} to segment satellite imagery.
Sadly, after some research, in the available timeframe, nothing seemed to correspond to what was needed in order to
apply the same technic to this work.
Fortunately, during those research, the already pretrained model~\textcite{bosch_journal_2020} was found.
It applies an already existing technics to segment tree/non-tree pixels.
Therefore, the goal becomes to segment trees and consider that everywhere else, the robot would be able to traverse
or at least find a traversable path avoiding not segmented out obstacles (\textit{e.g.}\ negative obstacles, rocks, etc.).

The \gls{ai} model proposed is train using supervised learning using the following steps.
First, images are split in tiles and in order to reduce cost of labelling tiles while keeping variety in the dataset,
using GIST descriptors, k means clusters the tiles.
k is chosen so that the number of clusters is about 1\% the number of tiles.
Then only the tiles closest to the centroids are labelled, either manually or using other available data (\textit{e.g.}\ \gls{lidar} measurements).
Using these labelled tiles as ground truth, a binary Adaboost classifier is train.
The input vector for each pixel is twenty-seven features long, 6 encoding color, 18 texture and 3 entropy.
Finally, a refinement method is used to avoid sparse pixels.

\begin{figure}
    \begin{subfigure}[t]{.32\textwidth}
        \includegraphics[width=0.99\linewidth]{illustrations/topological_map_creation/detect_tree_b50_r10000}
        \caption{Segmentation of detect tree using the default refinement parameters ($\beta = 50$, $\text{rescale} = 10000$)}
    \end{subfigure}
    \hfill
    \begin{subfigure}[t]{.32\textwidth}
        \includegraphics[width=0.99\linewidth]{illustrations/topological_map_creation/detect_tree_b1000_r10000}
        \caption{Segmentation of detect tree using $\beta = 1000$, $\text{rescale} = 10000$}
    \end{subfigure}
    \hfill
    \begin{subfigure}[t]{.32\textwidth}
        \includegraphics[width=0.99\linewidth]{illustrations/topological_map_creation/detect_tree_b1000_r30000}
        \caption{Segmentation of detect tree using $\beta = 1000$, $\text{rescale} = 30000$}
    \end{subfigure}
    \caption{Segmentation of detect tree using \Cref{fig:fast_color:raw_image} as input.}
    \label{fig:detect_tree:results}
\end{figure}


The authors provide a version of their model trained on Zurich's Orthofoto Sommer 2014/15.
Inferring with this model on \Cref{fig:fast_color:raw_image} as input, gives the results in \Cref{fig:detect_tree:results}.
Furthermore, it shows different refinement parameters and how it affects the final results of the segmentation.
A higher value of $\beta$ seems to make the classification less noisy while a lower value does the opposite.

% TODO performance
% TODO manually label trees in aukerman and make a metric


% TODO post-processing (refined using erosion dilation)
% TODO on satellite map (not good enough)

Even though detect tree gave very promising results on \gls{uav} imagery, many more steps are required to be able
to use it, to create the backbone of the topological map (\textit{i.e.}\ placement of node and vertices).
As, with a carefully though \gls{ui}, this task can be done by a user in matter of minutes if not seconds, it seemed
more reasonable to focus the remaining time on developing methods to gather \gls{uav} data in chosen nodes and
make them recognisable by the \gls{ugv}.
